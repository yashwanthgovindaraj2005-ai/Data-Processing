# An Efficient Machine Learning System for Categorizing High-Volume Customer Support Tickets

## Overview
This project develops an **automated machine learning system** that classifies support tickets into four operational categories(Incident,Request,Problem,Change). The system uses Natural Language Processing (NLP) to understand ticket text and automatically route it to the right category, improving triage speed, accuracy, and customer satisfaction.

## Key Highlights
- Real-world dataset from Hugging Face
- Comprehensive text preprocessing pipeline
- Comparison of classical vs transformer models
- Handles class imbalance using SMOTE
- Word2Vec + RBF-SVM gives best overall performance
- Evaluates both accuracy and computational cost

## Project Objective
- To develop an accurate and computationally efficient machine learning system that automatically categorizes high-volume customer support tickets using Natural Language Processing.

## Dataset
- **Source**: HuggingFace — Customer Support Tickets Dataset
- **Total records**:  61,765
- **Final labeled samples used**: 48,587.

## System Architecture
- Data loading

- Text cleaning and normalization

- Tokenization and stopword removal

- Train–test split

- MOTE oversampling

- Text embedding generation

- ML model training and tuning

- Performance evaluation

## Algorithms Used
 **Embedding Techniques** 
| Embedding | Description                              |
| --------- | ---------------------------------------- |
| Word2Vec  | lightweight semantic word representation |
| BERT      | transformer-based contextual embedding   |
| RoBERTa   | optimized BERT variant                   |

 **Classification Algorithms** 
| Algorithm                                                | Notes                                  |
| -------------------------------------------------------- | -------------------------------------- |
| Support Vector Machine (Linear, RBF, Polynomial kernels) | best overall performance               |
| Multinomial Naive Bayes                                  | strong baseline for frequency features |
| Bernoulli Naive Bayes                                    | efficient for short text               |

## Evaluation Metrics
- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC 
- Training Time

## Results Summary
| Model              | Accuracy  | Notes      |
| ------------------ | --------  | ---------- |
| Word2Vec + RBF-SVM | ⭐0.83   | Best model |
| BERT + SVM         | 0.81      | High cost  |
| RoBERTa + SVM      | 0.79      | Slower     |



## Tools & Technologies Used
- Python
- NLTK (for preprocessing)
- Scikit-learn (for modeling)
- Gensim (for Word2Vec and Doc2Vec)
- Transformers
- Pandas & Numpy(For Data Cleaning)
- Matplotlib, Seaborn (for visualization)


## Challenges Faced
- **Class Imbalance**: This issue was addressed using **SMOTE oversampling**, but tuning the oversampling level without overfitting required experimentation.
- **Quality of the Dataset**: A large portion of records lacked category labels, which meant that many entries had to be removed before model training. This reduced the effective dataset size and required      additional  care to avoid bias.
- **Hyperparameter Optimization**: GridSearchCV across multiple classifiers and embeddings was slow, so a smaller tuning subset had to be used.Balancing model performance with available computational resources was therefore a recurring challenge throughout the project.

## Future Improvements
- Full transformer fine-tuning
- Multi-label ticket routing
- Multilingual classification
- API deployment

## Conclusion
- A combination of **Word2Vec embeddings** and **RBF SVM** delivers superior performance with significantly lower computational requirements, making it well-suited for real-time helpdesk systems.


